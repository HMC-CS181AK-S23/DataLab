{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c05a8865",
      "metadata": {
        "id": "c05a8865"
      },
      "outputs": [],
      "source": [
        "# Here are all the imports I used. You're welcome to change these.\n",
        "import csv\n",
        "from collections import Counter\n",
        "import json\n",
        "from lxml import etree as ET\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "import sqlite3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Working Independently with Text Data\n",
        "\n",
        "This lab has a few different purposes:\n",
        "\n",
        "At a *technical level*, I want to make sure you've worked with CSV, JSON, and XML data, as well as a lightweight SQL-style database. Ad-hoc interactions with these sorts of data are likely to happen in your computing future, and I want you to have a bit of experience of how to manipulate data across these formats and an idea of where you could find out more.\n",
        "\n",
        "At a *meta level*, I want you to get some practice being a self-sufficient programmer. Lots of programmers underestimate our own ability to figure out answers on our own - whether because of impostor syndrome, bad past experiences with a technology, or just nerves.\n",
        "\n",
        "If data parsing and database querying skills are all old hat to you, then I hope you take the opportunity to go spelunking in a couple of datasets that are funkier than they look. If you're new to these, this lab is for you. You've got this.\n",
        "\n",
        "Some resources that might help throughout this lab:\n",
        "* [TutorialsPoint: How to read and write unicode UTF-8 files in Python](https://www.tutorialspoint.com/How-to-read-and-write-unicode-UTF-8-files-in-Python)\n",
        "* [W3C Python list comprehensions](https://www.w3schools.com/python/python_lists_comprehension.asp)\n",
        "* [collections module](https://docs.python.org/3/library/collections.html)\n",
        "* [csv module](https://docs.python.org/3/library/csv.html)\n",
        "* [json module](https://docs.python.org/3/library/json.html)\n",
        "* [lxml.etree tutorial](https://lxml.de/tutorial.html)\n",
        "* [matplotlib plot types](https://matplotlib.org/stable/plot_types/index.html)\n",
        "* [seaborn overview](https://seaborn.pydata.org/tutorial/function_overview.html)\n",
        "* [W3C SQL Introduction](https://www.w3schools.com/sql/sql_intro.asp)\n",
        "* [sqlite3 module](https://docs.python.org/3/library/sqlite3.html)\n",
        "* [xml module](https://docs.python.org/3/library/xml.etree.elementtree.html)\n",
        "\n",
        "## Setting up\n",
        "To get set up with this lab, you're going to connect Colab with a local running version of Jupyter Notebook. First, make sure you can get Jupyter Notebook started on your computer. Next, open up [Google Colab](https://colab.research.google.com/) and select \"Upload\", and upload the .ipynb from your starting repository.\n",
        "\n",
        "Next, on the command line for your computer, run the following command from the folder where you downloaded this assignment:\n",
        "\n",
        "```\n",
        "jupyter notebook --NotebookApp.allow_origin='https://colab.research.google.com' --port=8888  --NotebookApp.port_retries=0\n",
        "```\n",
        "\n",
        "This should output a URL for your local instance of Jupyter, something like `http://localhost:8888/?token=blahblahblah`. On Colab, use the dropdown menu in the top-right for *Connect*, select **Connect to a local runtime** and paste in the URL you got in this previous step. If you run into issues, follow Colab's linked instructions for debugging. Once you get a *Connected (Local)* indicator on the top-right, you can click the folder icon on the left nav bar to open the **Files** view on the right, and can refresh it using the second button on the right toolbar (a folder with a loopy arrow) to verify you can see all the lab files in there."
      ],
      "metadata": {
        "id": "nHo2NTe03zFC"
      },
      "id": "nHo2NTe03zFC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write your answer to each question in the text cell for that question.** Under each question, leave as many code cells as you want to show how you got your answer. You should remove code that didn't contribute to the answer, but keep code representing intermediate steps/reorganizing data to find an answer: it should be possible to re-run all the code cells from the beginning of this file to get to your answer.\n",
        "\n",
        "Unlike previous labs, I'm not going to give you exact pointers here for what code to write to answer these questions. However, I am going to provide some links to help you with some of these steps, and you're welcome to talk to grutors or me if you're stuck. You are welcome to search for other answers; if you borrow code (even if you modify it) from e.g. a StackOverflow post or web tutorial, please put a link to the tutorial in the first cell that uses it as a comment, e.g.\n",
        "\n",
        "```python\n",
        "# following https://docs.python.org/3/library/csv.html#csv.reader\n",
        "with open('TMDb_updated.CSV', newline='') as csvfile:\n",
        "    data_reader = csv.reader(csvfile)\n",
        "```\n",
        "\n",
        "If all you're doing is inspecting a file, no need to put fake code in or to do it in Colab at all: it's likely much easier just to open things directly on your computer. However, it may be nice to copy/paste in a small sample or example to show what you're writing about."
      ],
      "metadata": {
        "id": "ZNRGeGYh5iyP"
      },
      "id": "ZNRGeGYh5iyP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Started: CSVs and XML\n",
        "\n",
        "The first task is to load the data in TMDb_updated.CSV. This is a comma-separated values file generated by Sankha Subhra Mondal from the IMDb API listing the top 10,000 most popular movies. While the dataset is updated on a weekly basis, this version (version 152) was downloaded on March 17, 2023. You can find out more about the data [here](https://www.kaggle.com/datasets/sankha1998/tmdb-top-10000-popular-movies-dataset). It's worth noting that this data includes non-ASCII characters and is encoded with UTF-8."
      ],
      "metadata": {
        "id": "RSm9_kgSY5py"
      },
      "id": "RSm9_kgSY5py"
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. How many unique titles are there among the 10,000 titles in the TMDb data? What's an example of a movie title that shows up at least three times?"
      ],
      "metadata": {
        "id": "azb-HPaiKvVZ"
      },
      "id": "azb-HPaiKvVZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. How many movie titles of the 10,000 total movies have a non-ASCII character in them? Give a couple of examples."
      ],
      "metadata": {
        "id": "B5NM2KxLLKRY"
      },
      "id": "B5NM2KxLLKRY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Visualize the distribution over ratings as a histogram with 99 buckets. What are a few things you notice?"
      ],
      "metadata": {
        "id": "WDWxCmifLwTF"
      },
      "id": "WDWxCmifLwTF"
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Ask and answer one other question about these movie data."
      ],
      "metadata": {
        "id": "ZqFM0Yr-MLhv"
      },
      "id": "ZqFM0Yr-MLhv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Write out the movie data to an XML file using default ASCII formatting. The structure should look like this (though you may sort them in whatever order you want):\n",
        "\n",
        "```xml\n",
        "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
        "<movies>\n",
        "  <movie id=\"3727\" lang=\"fr\">\n",
        "    <title>#Iamhere</title>\n",
        "    <rating>5.5</rating>\n",
        "    <description>St&#233;phane lives a quiet life as an eminent French Chef but when he decides to visit Soo, a mysterious Korean lady he fell in love with on Instagram, he'll embark on an adventurous journey full of discoveries.</description>\n",
        "  </movie>\n",
        "  <movie id=\"2536\" lang=\"en\">\n",
        "    <title>#RealityHigh</title>\n",
        "    <rating>6.4</rating>\n",
        "    <description>When nerdy high schooler Dani finally attracts the interest of her longtime crush, she lands in the cross hairs of his ex, a social media celebrity.</description>\n",
        "  </movie>\n",
        "    ...\n",
        "  <movie id=\"1719\" lang=\"it\">\n",
        "    <title>&#200; per il tuo bene</title>\n",
        "    <rating>8</rating>\n",
        "    <description>Three families go into crisis when their daughters get engaged. Three desperate fathers see their worst nightmare come true: they are convinced that their young daughters have all chosen a wrong boyfriend. Sure to act for their own good, they will join forces to get rid of the three suitors as soon as possible, putting a strain on the patience of their wives so much that they risk wrecking their own marriages. In the end, the good will win, but who will?</description>\n",
        "  </movie>\n",
        "  <movie id=\"1318\" lang=\"ru\">\n",
        "    <title>&#1057;&#1084;&#1086;&#1090;&#1088;&#1080; &#1082;&#1072;&#1082; &#1103;</title>\n",
        "    <rating>0</rating>\n",
        "    <description>Escaping from the orphanage, a desperate kid Olga accidentally meets Maxim, a blind guy who is tired of the quirks of a rich father. Having concluded a deal, they go on a road trip. Despite his peculiarity, Max manages to find a way out of the most incredible troubles and makes Olya look at the world differently.</description>\n",
        "  </movie>\n",
        "</movies>\n",
        "```"
      ],
      "metadata": {
        "id": "fuFLGcpGMNKV"
      },
      "id": "fuFLGcpGMNKV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Looking through the file, you should see a number of places with sequences starting with `&` and ending with `;`, e.g. `&#8212;`. What are these? What does the number 8212 mean in this context?"
      ],
      "metadata": {
        "id": "Hz0nB2qwMhEI"
      },
      "id": "Hz0nB2qwMhEI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "7. Overwrite the file, this time using a UTF-8 encoding to write it out. While most of the above sequences are gone, there are still lots of `&amp;` sequences. What are these, and why didn't they change?"
      ],
      "metadata": {
        "id": "7tPMNXB9Mirw"
      },
      "id": "7tPMNXB9Mirw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## JSON with a larger dataset\n",
        "\n",
        "We're going to move on to a different movie dataset: this one uses Wikipedia instead of IMDb as its source. It's a slightly modified version of the Wikipedia Plot Summaries dataset constructed by Justin R. You can find out more about the dataset [here](\n",
        "https://www.kaggle.com/datasets/jrobischon/wikipedia-movie-plots).\n",
        "\n",
        "To get the modified version, you'll need to download it from here:\n",
        "https://cs.hmc.edu/~xanda/wiki_movies.csv. (You don't have to do this using Python.) Make sure it's in the same folder and that you don't try to commit it to Github, as it'll get cranky about the large file size."
      ],
      "metadata": {
        "id": "_3Bf02dYM-XB"
      },
      "id": "_3Bf02dYM-XB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. What year do you think this data was originally collected, and why? (Kaggle says the dataset was posted in 2019, but it's not clear that's the origination date.)"
      ],
      "metadata": {
        "id": "nAJs2HzqO3lb"
      },
      "id": "nAJs2HzqO3lb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Find an example of a row that stretches across more than one line of text in the original CSV. How does the CSV format make sure to capture multiple lines as one row?"
      ],
      "metadata": {
        "id": "ktylrLPJQUj4"
      },
      "id": "ktylrLPJQUj4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Look through the 100 most common genres in the dataset. What are three interesting/surprising things you notice about the genre listings?"
      ],
      "metadata": {
        "id": "hILsR_9TQZmK"
      },
      "id": "hILsR_9TQZmK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Create a json file that contains only the data for movies that don't have `unknown`, `Unknown`, ` `, or `` listed as their director or genre. Remove the field for `Cast` before doing this, as it's often blank/malformed and difficult to interpret. Use pretty printing options to indent lines (with 2-space indentation) to help readability. My file has 254981 lines in it."
      ],
      "metadata": {
        "id": "66-I3TJ3QnQ3"
      },
      "id": "66-I3TJ3QnQ3"
    },
    {
      "cell_type": "markdown",
      "id": "51655afb",
      "metadata": {
        "id": "51655afb"
      },
      "source": [
        "12. How does JSON render non-ASCII characters in the file? How does it differ from XML?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading data in SQL\n",
        "\n",
        "There are lots of different databases and ways to interact with them. A super-simple starting point for interacting with SQL-style databases (one of the most popular query languages out there) is SQLite, which stores data as a static file on a file server, even though the interface for interaction will look a lot like making a connection to a networked database. We're going to use SQLite to practice a little basic querying.\n",
        "\n",
        "A sloppy overview of SQL databases if you haven't worked with them before: A SQL database is organized into different tables of data. Each table has a list of variables it keeps track of (*columns*), and each data entry (*row*) in the database defines values for these variables. Typically, one column in a table needs to have a unique value for each row so that it's possible to index data with repeat values in other columns: this indexing column is typically called the *primary key*. The listing of tables' columns and their types are is called a *schema*.\n",
        "\n",
        "The first few steps won't have a text answer: they'll just require writing and running some code to get your database set up. Just make sure to include that code below."
      ],
      "metadata": {
        "id": "1zQBmOxORI7s"
      },
      "id": "1zQBmOxORI7s"
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. Create a SQLite database called `movies.db`. Load all of the imdb movie data into a table called `imdb_movies` with columns `id`, `title`, `lang`, `rating`, and `description`. Give types for each of these. `id` should be the primary key. (Hint: `sqlite3` has some support for inserting lots of rows of data at once that should run a lot faster than a Python for loop.)"
      ],
      "metadata": {
        "id": "b3hNsA08T7Nc"
      },
      "id": "b3hNsA08T7Nc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. Load all of the filtered wikipedia movie data into a table called `wiki_movies` with columns `id`, `release_year`, `title`, `director`, `origin`, `genre`, `url`, and `plot`. Specify types for each of these columns. `id` should be the primary key, which needs a unique integer for each entry -- since this dataset doesn't include these already, you'll need to generate these for each entry as you load."
      ],
      "metadata": {
        "id": "xR5cenM7UKpR"
      },
      "id": "xR5cenM7UKpR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. How many movies in `imdb_movies` start with the title The Lion King? What are their titles?"
      ],
      "metadata": {
        "id": "PPfejLsCUe_Q"
      },
      "id": "PPfejLsCUe_Q"
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. How many distinct languages are there in the `imdb_movies` data?"
      ],
      "metadata": {
        "id": "3QXmDcAzUiMa"
      },
      "id": "3QXmDcAzUiMa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. How many movies in the `wiki_movies` data were released in the 1920s?"
      ],
      "metadata": {
        "id": "T99QPUgcVlCr"
      },
      "id": "T99QPUgcVlCr"
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. Perform an inner join based on exact matches for title between the `wiki_movies` and `imdb_movies`. How many rows does this generate?"
      ],
      "metadata": {
        "id": "rBvqWuoZVult"
      },
      "id": "rBvqWuoZVult"
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. How many movies have the title \"Dracula\" in the inner joined set? Why?"
      ],
      "metadata": {
        "id": "_pRKTvWMV1c2"
      },
      "id": "_pRKTvWMV1c2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. How many movies have Pokémon in their title in this inner join? Why? (Hint: there are definitely Pokémon movies in both datasets!)"
      ],
      "metadata": {
        "id": "YTietstYWYB8"
      },
      "id": "YTietstYWYB8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. Use a left outer join with `imdb_movies` and `wiki_movies` to find out: did movies in the `imdb_movies` dataset that came out before 2000 average a higher or a lower rating than movies that came out on or after 2000?"
      ],
      "metadata": {
        "id": "vUYDAC4AWZDv"
      },
      "id": "vUYDAC4AWZDv"
    },
    {
      "cell_type": "markdown",
      "id": "ec7a159e",
      "metadata": {
        "id": "ec7a159e"
      },
      "source": [
        "22. Ask and answer one other question of your choosing that requires interacting with both datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When you're done, you'll submit your file by putting the URL in Sakai. Before you do so, please make sure to add the grutors using the **Share** button on the top right of Colab: cs181ak-grutors-l@g.hmc.edu"
      ],
      "metadata": {
        "id": "_gNS1a9tXQTj"
      },
      "id": "_gNS1a9tXQTj"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}